{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaadb1e-4bf6-4eae-ab18-a25f50ff5e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64817,) (7202,)\n"
     ]
    }
   ],
   "source": [
    "#首先将用到的包进行导入\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import model_selection\n",
    "\n",
    "#将数据进行读取\n",
    "data=pd.read_csv('评论汇总-分词后.csv',index_col=0)\n",
    "\n",
    "# 现在是划分数据集\n",
    "# random_state 取值，这是为了在不同环境中，保证随机数取值一致，以便验证模型的实际效果。\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(data.分词.values.astype('U'), data.分数.values,\n",
    "                                                                    test_size=0.1, random_state=1)\n",
    "\n",
    "# 划分完毕，查看数据形状\n",
    "print(train_x.shape, test_x.shape)\n",
    "# train_x 训练集数据 test_x 测试集数据  train_y训练集的标签 test_y 测试集的标签\n",
    "#定义函数，从哈工大中文停用词表里面，把停用词作为列表格式保存并返回 在这里加上停用词表是因为TfidfVectorizer和CountVectorizer的函数中\n",
    "#可以根据提供用词里列表进行去停用词\n",
    "def get_stopwords(stop_word_file):\n",
    "    custom_stopwords_list = [line.strip() for line in open(stop_word_file, encoding='UTF-8').readlines()]\n",
    "    return custom_stopwords_list\n",
    "\n",
    "#获得由停用词组成的列表\n",
    "stop_words_file = 'cn_stopwords.txt'\n",
    "stopwords = get_stopwords(stop_words_file)\n",
    "\n",
    "'''\n",
    "使用TfidfVectorizer()和 CountVectorizer()分别对数据进行特征的提取，投放到不同的模型中进行实验\n",
    "'''\n",
    "# 开始使用TF-IDF进行特征的提取，对分词后的中文语句做向量化。\n",
    "# 引进TF-IDF的包\n",
    "TF_Vec = TfidfVectorizer(max_df=0.8,\n",
    "                         min_df=3,\n",
    "                         stop_words=frozenset(stopwords)\n",
    "                         )\n",
    "# 拟合数据，将数据准转为标准形式，一般使用在训练集中\n",
    "train_x_tfvec = TF_Vec.fit_transform(train_x)\n",
    "# 通过中心化和缩放实现标准化，一般使用在测试集中\n",
    "test_x_tfvec = TF_Vec.transform(test_x)\n",
    "\n",
    "'''\n",
    "使用KNN模型\n",
    "'''\n",
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "start_time = time.time()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "min = 1\n",
    "max = 10\n",
    "test1 = []\n",
    "test2 = []\n",
    "\n",
    "for i in range(min, max):\n",
    "    #创建模型\n",
    "    Kn = KNeighborsClassifier()\n",
    "    #拟合从tf-idf拿到的数据\n",
    "    Kn.fit(train_x_tfvec,train_y)\n",
    "    #在训练时查看训练集的准确率\n",
    "    pre_train_y = Kn.predict(train_x_tfvec)\n",
    "    #在训练集上的正确率\n",
    "    train_accuracy = accuracy_score(pre_train_y,train_y)\n",
    "    #训练结束查看预测 输入测试集查看预测\n",
    "    pre_test_y = Kn.predict(test_x_tfvec)\n",
    "    #查看在测试集上的准确率\n",
    "    test_accuracy = accuracy_score(pre_test_y,test_y)\n",
    "    test1.append(train_accuracy)\n",
    "    test2.append(test_accuracy) \n",
    "\n",
    "plt.plot(range(min+1,max+1), test1, color = 'red', label = \" max_depth_train\")\n",
    "plt.plot(range(min+1,max+1), test2, color = 'blue', label = \" max_depth_test\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print('使用TfidfVectorizer提取特征使用KNN分类器的准确率\\n训练集：{0}\\n测试集：{1}'.format(train_accuracy,test_accuracy))\n",
    "end_time = time.time()\n",
    "print('使用KNN分类器的程序运行时间为：',end_time - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c25936-fd22-4edb-ad2a-26007507e25a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
